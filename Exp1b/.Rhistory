corrplot(df[,c('correctratio','age','SBSOD','Anxiety','ExploreTendency','GPS','nfc','wsp','crt2_correct','fii','restraint','impulsitivity','visualizer','verbalizer')], method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
library(RColorBrewer)
library(corrplot)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(df[,c('correctratio','age','SBSOD','Anxiety','ExploreTendency','GPS','nfc','wsp','crt2_correct','fii','restraint','impulsitivity','visualizer','verbalizer')])
M<-cor(df[,c('correctratio','age','SBSOD','Anxiety','ExploreTendency','GPS','nfc','wsp','crt2_correct','fii','restraint','impulsitivity','visualizer','verbalizer')])
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
setwd("~/Documents/Research/Forth_Year_Projects/MentalRotation")
#read data
library(haven)
library(tidyverse)
library(RColorBrewer)
library(corrplot)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(df[age<35,c('correctratio','age','SBSOD','Anxiety','ExploreTendency','GPS','nfc','wsp','crt2_correct','fii','restraint','impulsitivity','visualizer','verbalizer')])
names(df)
library(RColorBrewer)
library(corrplot)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(df[age<35,c('correctratio','age','SBSOD','Anxiety','ExploreTendency','GPS','nfc','wsp','crt2_correct','fii','restraint','impulsitivity','visualizer','verbalizer')])
library(RColorBrewer)
library(corrplot)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
# matrix of the p-value of the correlation
p.mat <- cor.mtest(df[df$age<35,c('correctratio','age','SBSOD','Anxiety','ExploreTendency','GPS','nfc','wsp','crt2_correct','fii','restraint','impulsitivity','visualizer','verbalizer')])
M<-cor(df[df$age<35,c('correctratio','age','SBSOD','Anxiety','ExploreTendency','GPS','nfc','wsp','crt2_correct','fii','restraint','impulsitivity','visualizer','verbalizer')])
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(M, method="color", col=col(200),
type="upper", order="hclust",
addCoef.col = "black", # Add coefficient of correlation
tl.col="black", tl.srt=45, #Text label color and rotation
# Combine with significance
p.mat = p.mat, sig.level = 0.01, insig = "blank",
# hide correlation coefficient on the principal diagonal
diag=FALSE
)
install.packages("tableone")
install.packages("Matching")
install.packages("MatchIt")
library(tableone)
library(Matching)
#Now load the lalonde data (which is in the MatchIt package):
library(MatchIt)
data(lalonde)
force(lalonde)
View(mrtraw)
names(lalonde)
age <- as.numeric(lalonede$age)
educ <- as.numeric(lalonde$educ)
black <- as.numeric(lalonede$race =="black")
hispan <- as.numeric(lalonede$race == "hispan")
married <- as.numeric(lalonede$married)
nodegree <- as.numeric(lalonede$nodegree)
re74 <- as.numeric(lalonede$re74)
re75 <- as.numeric(lalonede$re75)
re78 <- as.numeric(lalonde$re78)
treatment <- as.numeric(lalonde$treat)
age <- as.numeric(lalonde$age)
educ <- as.numeric(lalonde$educ)
black <- as.numeric(lalonde$race =="black")
hispan <- as.numeric(lalonde$race == "hispan")
married <- as.numeric(lalonde$married)
nodegree <- as.numeric(lalonde$nodegree)
re74 <- as.numeric(lalonde$re74)
re75 <- as.numeric(lalonde$re75)
re78 <- as.numeric(lalonde$re78)
treatment <- as.numeric(lalonde$treat)
mydata <- data.frame(cbind(age,educ,black,hispan,married,nodegree,re74,re75,treatment,re78))
xvars <- c("age","educ","black","hispan","married","nodegree","re74","re75")
table1 <- CreateTableOne(vars=xvars,strata = "treatment",data=mydata,test=FALSE)
print(table1,smd=TRUE)
mean(mydata[mydata$treatment==1,]$re78)-mean(mydata[mydata$treatment==0,]$re78)
psmodel <- glm(treatment~age+educ+black+hispan+married+nodegree+re74+re75,family = binomial(),data=mydata)
pscore <- psmodel$fitted.values
summary(pscore)
set.seed(931139)
set.seed(931139)
psmatch <- Match(Tr=mydata$treatment,M=1,X=pscore,replace=FALSE)
matched <- mydata[unlist(psmatch[c("index.treated","index.control")]),]
matchedtab1 <- CreateTableOne(vars = xvars,strata = "treatment",data=matched,test=FALSE)
print(matchedtab1,smd=TRUE)
psmatch_ca <- Match(Tr=mydata$treatment,M=1,X=pscore,replace=FALSE,caliper = .2)
matched2 <- mydata[unlist(psmatch_ca[c("index.treated","index.control")]),]
matchedtab2 <- CreateTableOne(vars = xvars,strata = "treatment",data=matched2,test=FALSE)
print(matchedtab2,smd=TRUE)
mean(matched2[matched2$treatment==1,]$re78)-mean(matched2[matched2$treatment==0,]$re78)
t.test(matched2$re78,matched2$treatment)
t.test(matched2$re78~matched2$treatment)
t.test(matched2$re78~matched2$treatment,paired = T)
set.seed(931139)
psmatch_ca <- Match(Tr=mydata$treatment,M=1,X=pscore,replace=FALSE,caliper = .1)
matched2 <- mydata[unlist(psmatch_ca[c("index.treated","index.control")]),]
matchedtab2 <- CreateTableOne(vars = xvars,strata = "treatment",data=matched2,test=FALSE)
print(matchedtab2,smd=TRUE)
mean(matched2[matched2$treatment==1,]$re78)-mean(matched2[matched2$treatment==0,]$re78)
t.test(matched2$re78~matched2$treatment,paired = T)
install.packages("ipw")
install.packages("survey")
#install.packages("MatchIt")
library(tableone)
library(Matching)
library(ipw)
library(survey)
library(MatchIt)
install.packages("survey")
library(tableone)
library(Matching)
library(ipw)
library(survey)
library(MatchIt)
summary(pscore)
weight <- ifelse(treatment == 1, 1/(pscore),1(1-pscore))
weight <- ifelse(treatment == 1, 1/(pscore),1(1-pscore))
ps <- predict(psmodel,type = "response")
ps <- predict(psmodel,type = "response")
weight <- ifelse(treatment==1, 1/(ps),1(1-ps))
weight <- ifelse(treatment==1, 1/(ps),1/(1-ps))
summary(weight)
weightedData <- svydesign(ids = ~1,data = mydata,weights = ~weight)
weightedtable <- svyCreateTableOne(vars = xvars,strata = "treatment",data=weightedData,test=FALSE)
print(weightedtable,smd=TRUE)
msm <- svyglm(re78~treatment,design=weightedData)
coef(msm)
confint(msm)
weightmodel <- ipwpoint(exposure = treatment,family="gaussian",link="identity",denominator = ~age+educ+black+hispan+married+nodegree+re74+re75,data=mydata,trunc = .01)
mydata$wt <- weightmodel$weights.trun
weightedData <- svydesign(ids = ~1,data = mydata,weights = ~wt)
weightedtable <- svyCreateTableOne(vars = xvars,strata = "treatment",data=weightedData,test=FALSE)
msm <- svyglm(re78~treatment,design=weightedData)
coef(msm)
confint(msm)
?ipwpoint
weightmodel <- ipwpoint(exposure = treatment,family = "binomial",link="logit",denominator = ~age+educ+black+hispan+married+nodegree+re74+re75,data=mydata,trunc = .01)
mydata$wt <- weightmodel$weights.trun
weightedData <- svydesign(ids = ~1,data = mydata,weights = ~wt)
weightedtable <- svyCreateTableOne(vars = xvars,strata = "treatment",data=weightedData,test=FALSE)
msm <- svyglm(re78~treatment,design=weightedData)
coef(msm)
confint(msm)
print(table1,smd=TRUE)
mean(mydata[mydata$treatment==1,]$re78)-mean(mydata[mydata$treatment==0,]$re78)
pscore <- psmodel$fitted.values
summary(pscore)
print(matchedtab1,smd=TRUE)
set.seed(931139)
psmatch_ca <- Match(Tr=mydata$treatment,M=1,X=pscore,replace=FALSE,caliper = .1)
matched2 <- mydata[unlist(psmatch_ca[c("index.treated","index.control")]),]
matchedtab2 <- CreateTableOne(vars = xvars,strata = "treatment",data=matched2,test=FALSE)
print(matchedtab2,smd=TRUE)
mean(matched2[matched2$treatment==1,]$re78)-mean(matched2[matched2$treatment==0,]$re78)
t.test(matched2$re78~matched2$treatment,paired = T)
library(foreign)
library(ggplot2)
library(RColorBrewer)
setwd("~/Documents/Research/Third Year Project/WalkingDSP")
WDSP <- read.csv("Test-testphase1.csv")
p1 <- ggplot(WDSP, aes(x=X, y=Y) ) +
stat_density_2d(aes(fill = ..density..), geom = "raster", contour = FALSE) +
scale_fill_distiller(palette= "RdYlGn", direction=-1) +
#  scale_x_continuous(limits = c(-8,10)) +
#  scale_y_continuous(limits = c(-10,8)) +
theme_void()+
theme(legend.position='none')
p1
p1 <-  ggplot(WDSP,aes(x=X,y=Y))+geom_point()
ggsave("plot003.png",p1)
WDSP2 <- read.csv("Test-testphase2.csv")
p2 <- ggplot(WDSP2, aes(x=X, y=Y) ) +
stat_density_2d(aes(fill = ..density..), geom = "raster", contour = FALSE) +
scale_fill_distiller(palette= "RdYlGn", direction=-1) +
#  scale_x_continuous(limits = c(-8,10)) +
#  scale_y_continuous(limits = c(-10,8)) +
theme_void()+
theme(legend.position='none')
p2
p2 <-  ggplot(WDSP2,aes(x=X,y=Y))+geom_point()
ggsave("plot007.png",p2)
WDSP_p_female <- read.csv("Pilot-female.csv")
p3 <- ggplot(WDSP_p_female, aes(x=X, y=Y) ) +
stat_density_2d(aes(fill = ..density..), geom = "raster", contour = FALSE) +
scale_fill_distiller(palette= "RdYlGn", direction=-1) +
#  scale_x_continuous(limits = c(-8,10)) +
#  scale_y_continuous(limits = c(-10,8)) +
theme_void()+
theme(legend.position='none')
p3
setwd("~/Documents/Research/Third Year Project/WalkingDSP/Summary")
library(tidyverse)
IniCod <- read.csv("InitialCoding.csv")
levels(IniCod$Gender)
IniCod$Gender <- recode(IniCod$Gender,
" f\n"="female",
" m\n"="male")
levels(IniCod$Strategy)
IniCod %>%
group_by(Participant.No,Strategy)%>%
tally()
ggplot(NIFdataSum, aes(x=Condition, y=SI,color=sex))+
geom_boxplot(outlier.shape = NA)+
geom_jitter(position=position_jitterdodge(0.5), cex=1.2)+
theme_grey(base_size = 22)
NIFdataSum <- IniCod %>%
group_by(Participant.No)%>%
summarise(
success=20-sum(Strategy=="failure"),
SI=sum(Strategy=="shortcut")/success,
sex=unique(Gender)
)
NIFdataSum$Condition=c(rep("desktop",9),rep("iVR",9))
ggplot(NIFdataSum, aes(x=Condition, y=SI,color=sex))+
geom_boxplot(outlier.shape = NA)+
geom_jitter(position=position_jitterdodge(0.5), cex=1.2)+
theme_grey(base_size = 22)
#ggsave("SI_ConditionBySex.png")
setwd("~/Documents/Research/Third Year Project/Pointing Task/20Winter/Shortcutting-prior/learning")
library(tidyverse)
df <- read.csv("PointingDSP_learning.csv")
df_simple <- df[df$Time<100,]
set.seed(123)
df_sample <- df_simple[sample(nrow(df_simple),100000),]
df_sample$PartNo <- as.factor(df_sample$PartNo)
df_sample$PartGen <- as.factor(df_sample$PartGen)
ggplot(df_sample,aes(x=x,y=z,color=PartGen))+
geom_point(alpha=0.01)+
facet_wrap("PartGen")
ggplot(df_sample,aes(x=x,y=z,color=PartGen))+
geom_point(alpha=0.1)+
facet_wrap("PartNo")
ggplot(df[df$PartNo%in%c("670","669","666","636","628","647")&df$Time<90,],aes(x=x,y=z,color=as.factor(PartGen)))+
geom_point()+
scale_color_manual(name="Sex",labels=c("female","male"),values=c('#D4D4D4','#000000'))+
facet_wrap("PartNo")+
theme_bw(base_size = 25)+
theme(legend.text = element_text(size = 28))+
guides(colour = guide_legend(override.aes = list(size=6)))
#ggsave("sampleParticipantsDSP2.png",width = 13,height = 7)
setwd("~/Documents/Research/Forth_Year_Projects/VSWM/PeriPaper/data/OpenScienceShare/Exp1b")
## ---------------------------
##
## Script name: Exp1b_MainAnalysis
##
## Purpose of script: Experiment 1b data cleaning and EDA and analysis
##
## Author: Chuanxiuyue (Carol) He
##
## Date Created: 2021-05-20
##
## Email: carol.hcxy@gmail.com
##
## Content:
##      1. Load Experiment 1b Data
##      2. Experiment 1b Data Cleaning
##      3. Accuracy Descriptive Statistics
##      4. Signal Detection Theory
##      5. Bias Calculation
##      6. Bias Descriptive Statistics
##      7. d' Calculation
##      8. d' Descriptive Statistics
##      9. d' ANOVA
## ---------------------------
## ---------------------------
## set working directory for Mac and PC
setwd("~/CarolHe/")      # Carol's working directory (mac)
setwd("C:/Users/carolhe/")    # if using PC
## ---------------------------
## load up the packages
## use install.packages() to install new packages
library(tidyverse)
library(reshape2)
library(psych) # descriptive statistics
library(effectsize)
## ---------------------------
#####----------Load Experiment 1a Data----------#####
## read txt files
txt_files_ls <-  list.files(
path=getwd(),
pattern = "*.txt")
txt_files_df <- lapply(txt_files_ls,
function(x)
{
tmp <- try(read.table(
file = x,
header = TRUE,
sep=";"))
if (!inherits(tmp,
'try-error'))
tmp
}
)
## combine all txt files together
combined_df <- do.call("rbind",
lapply(txt_files_df,
as.data.frame)
)
#####----------Experiment 1a Data Cleaning----------#####
## finds -99999 values in the accuracy column and sets them to NA so that we can omit them and saving a new data frame
combined_df$accuracy[combined_df$accuracy == -99999] <- 0
## finds timed-out trials and sets them to NA
combined_df$time[combined_df$time == -1] <- NA
## no dual task trials set as NA
combined_df$dualTaskAcc[combined_df$dualTaskAcc == -99] <- NA
## performance on the concurrent verbal task:
v_df <- na.omit(combined_df)
v_perf <- aggregate(v_df$dualTaskAcc,
list(subject=v_df$subject),
mean)
names(v_perf) [2] <- "VerbTaskAcc"
## performance on the change detection task:
Exp1_cdt <- aggregate(combined_df$accuracy,
list(subject=combined_df$subject,
dim = combined_df$setName,
nUs = combined_df$nUnits,
change=combined_df$change),
mean)
names(Exp1_cdt)[5] <- "acc"
## poor performance in the concurrent verbal task
v_perf <- v_perf[v_perf$VerbTaskAcc>=0.8,]
## exclude low verb_acc participants
Exp1_cdt <- Exp1_cdt[Exp1_cdt$subject %in% v_perf$subject,]
## exclude participants with low acc in change detection task
c_perf <- aggregate(Exp1_cdt$acc,
list(subject=Exp1_cdt$subject),
mean)
names(c_perf) [2] <- "CDTAcc"
c_perf <- c_perf[c_perf$CDTAcc>0.5,]
Exp1_cdt <- Exp1_cdt[Exp1_cdt$subject %in% c_perf$subject,]
#####------Accuracy Descriptive Statistics-----#####
Exp1_descrp <- Exp1_cdt%>%
group_by(dim,nUs,change) %>%
dplyr::summarise(
count = n(),
mean = mean(acc, na.rm = TRUE),
se = sd(acc, na.rm = TRUE)/sqrt(count)
)
#####----------Signal Detection Theory----------#####
## recast Exp1 Structure Change Detection data
re_Exp1_cdt<-
recast(Exp1_cdt,
subject ~ dim + nUs + change,
id.var = c("subject", "dim",  "nUs", "change"))
names(re_Exp1_cdt) <- c("subject","cubes_n4_s","cubes_n4_d","cubes_n6_s","cubes_n6_d","cubes_n8_s","cubes_n8_d","squares_n4_s","squares_n4_d","squares_n6_s","squares_n6_d","squares_n8_s","squares_n8_d")
Exp1_fh <- re_Exp1_cdt %>%
mutate_at(c("cubes_n4_s","cubes_n6_s",
"cubes_n8_s","squares_n4_s","squares_n6_s",
"squares_n8_s"),
list(f=~ifelse(.==1,1/48,1-.)))%>%
mutate_at(vars(contains('_d')),
list(h=~ifelse(.==1,1-(1/48),ifelse(.==0,1/48,.))))%>%
mutate_at(vars(contains('_f'),contains('_h')),
list(z=~qnorm(.)))
#####----------Bias Calculation----------#####
Exp1_bias <- Exp1_fh %>%
mutate(cubes.n4.b=exp(-1*(cubes_n4_d_h_z^2-cubes_n4_s_f_z^2)*0.5))%>%
mutate(cubes.n6.b=exp(-1*(cubes_n6_d_h_z^2-cubes_n6_s_f_z^2)*0.5))%>%
mutate(cubes.n8.b=exp(-1*(cubes_n8_d_h_z^2-cubes_n8_s_f_z^2)*0.5))%>%
mutate(squares.n4.b=exp(-1*(squares_n4_d_h_z^2-squares_n4_s_f_z^2)*0.5))%>%
mutate(squares.n6.b=exp(-1*(squares_n6_d_h_z^2-squares_n6_s_f_z^2)*0.5))%>%
mutate(squares.n8.b=exp(-1*(squares_n8_d_h_z^2-squares_n8_s_f_z^2)*0.5))%>%
select(subject,contains('.b'))
## wide to long
Exp1_bias_long <- reshape(Exp1_bias,
direction = 'long',
idvar = 'subject',
varying = c(2:7),
timevar='dim',
times=c('cubes','squares'),
v.names=c('n4','n6','n8'))
Exp1_bias_long <- gather(Exp1_bias_long,
nUs,
bias,
n4:n8,
factor_key = T)
Exp1_bias_long$subject <- as.factor(Exp1_bias_long$subject)
#####----------Bias Descriptive Statistics----------#####
indivi_bias <- Exp1_bias_long%>%
group_by(subject) %>%
dplyr::summarise(
mean = mean(bias, na.rm = TRUE),
)
t.test(indivi_bias$mean,mu=1)
#####----------d' Calculation----------#####
Exp1_fh <- Exp1_fh%>%
mutate(cubes.n4.dp=cubes_n4_d_h_z-cubes_n4_s_f_z)%>%
mutate(cubes.n6.dp=cubes_n6_d_h_z-cubes_n6_s_f_z)%>%
mutate(cubes.n8.dp=cubes_n8_d_h_z-cubes_n8_s_f_z)%>%
mutate(squares.n4.dp=squares_n4_d_h_z-squares_n4_s_f_z)%>%
mutate(squares.n6.dp=squares_n6_d_h_z-squares_n6_s_f_z)%>%
mutate(squares.n8.dp=squares_n8_d_h_z-squares_n8_s_f_z)
Exp1_dpr <- Exp1_fh%>%
dplyr::select(subject,contains('.dp'))
## wide to long
Exp1_dpr_long <- reshape(Exp1_dpr,
direction = 'long',
idvar = 'subject',
varying = c(2:7),
timevar='dim',
times=c('cubes','squares'),
v.names=c('n4', 'n6','n8'))
Exp1_dpr_long <- gather(Exp1_dpr_long,
nUs,
dp,
n4:n8,
factor_key = T)
Exp1_dpr_long$dim <- as.factor(Exp1_dpr_long$dim)
Exp1_dpr_long$subject <- as.factor(Exp1_dpr_long$subject)
Exp1_dpr_long <-Exp1_dpr_long%>%
mutate(nUs_num = dplyr::case_when(
nUs == 'n4'  ~ 4,
nUs == 'n6'  ~ 6,
nUs == 'n8'  ~ 8))
#####--------d' Descriptive Statistics--------#####
Exp1_dpr_summary <- Exp1_dpr_long%>%
group_by(dim, nUs) %>%
dplyr::summarise(
count = n(),
mean = mean(dp, na.rm = TRUE),
se = sd(dp, na.rm = TRUE)/sqrt(count),
nUs_num = mean(nUs_num)
)
## visualization - line graph with error bars
#jpeg("Exp1b_dpr_line.jpeg", width = 8.5, height = 4.5, units = 'in', res = 300)
ggplot(Exp1_dpr_summary,aes(x=nUs_num,y=mean,color=dim,linetype=dim))+
geom_point(size=3)+
geom_line(size=1)+
geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=1,position=position_dodge(0),size=.8,linetype="solid")+
ylim(0,4)+
ylab('d\'')+
scale_x_continuous(name ="Units",breaks=c(4,6,8),limits=c(3,9))+
theme_classic(base_size = 20)+
scale_color_manual(values=c('#999999','#000000'))+
labs(colour="display type",linetype="display type")
#dev.off()
#####----------d' ANOVA----------#####
aov1 <- aov(dp~dim*nUs+Error(subject),data=Exp1_dpr_long)
summary(aov1)
eta_squared(aov1)
tapply(Exp1_dpr_long$dp,Exp1_dpr_long$dim,mean)
tapply(Exp1_dpr_long$dp,Exp1_dpr_long$dim,sd)
tapply(Exp1_dpr_long$dp,Exp1_dpr_long$nUs,mean)
tapply(Exp1_dpr_long$dp,Exp1_dpr_long$nUs,sd)
